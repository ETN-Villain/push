import json
import sqlite3
import os
from pathlib import Path

# Config: Your exact path (relative to script)
METADATA_DIR = Path('.')  # Current folder (VerdantKin)
DB_PATH = 'verdantkin_metadata.db'  # Output DB file (in same folder)

# Create/connect to SQLite DB with full template fields
conn = sqlite3.connect(DB_PATH)
c = conn.cursor()
c.execute('''CREATE TABLE IF NOT EXISTS nfts
             (token_id INTEGER PRIMARY KEY, name TEXT, description TEXT, 
              collection TEXT, image TEXT, fee_recipient TEXT, seller_fee_basis_points INTEGER,
              attack INTEGER, defense INTEGER, vitality INTEGER, 
              agility INTEGER, core INTEGER, background TEXT, 
              token_uri TEXT)''')

def parse_and_insert(file_path):
    try:
        token_id = int(file_path.stem)  # e.g., '343.json' â†’ 343
        with open(file_path, 'r') as f:
            data = json.load(f)
        
        # Extract top-level fields from template
        name = data.get('name', 'Unknown')
        description = data.get('description', '')
        collection = data.get('collection', 'Unknown')
        image = data.get('image', '')
        fee_recipient = data.get('fee_recipient', '')
        seller_fee_basis_points = int(data.get('seller_fee_basis_points', 0))
        token_uri = data.get('tokenURI', '') or str(file_path)
        
        # Extract traits from attributes array (force lowercase keys, handle display_type/max_value if present)
        attrs = {}
        for attr in data.get('attributes', []):
            key = attr['trait_type'].lower()
            value = attr.get('value', 'Unknown')
            # Parse numbers (ignore display_type/max_value for now)
            if isinstance(value, str) and value.isdigit():
                value = int(value)
            attrs[key] = value
        
        # Debug print for one file (remove after testing)
        if token_id == 343:  # Your example
            print(f"Debug for #343: Raw attrs keys = {list(attrs.keys())}")
            print(f"Background value: {attrs.get('background')}")
            print(f"Full parsed: {attrs}")
        
        # Insert with lowercase lookups (default to 0/'Common' if missing)
        background = str(attrs.get('background', 'Common'))
        c.execute('''INSERT OR REPLACE INTO nfts VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                  (token_id, name, description, collection, image, fee_recipient, seller_fee_basis_points,
                   int(attrs.get('attack', 0)), int(attrs.get('defense', 0)), int(attrs.get('vitality', 0)),
                   int(attrs.get('agility', 0)), int(attrs.get('core', 0)), 
                   background, token_uri))
        conn.commit()
        print(f"Inserted #{token_id}: {name} (Background: {background}, Attack: {attrs.get('attack', 'N/A')})")
    except Exception as e:
        print(f"Error processing {file_path.name}: {e}")

# Bulk load all .json files
json_files = list(METADATA_DIR.glob('*.json'))
print(f"Scanning {len(json_files)} files...")
for file_path in json_files:
    parse_and_insert(file_path)

# Summary query (rarity + other stats)
c.execute('SELECT background, COUNT(*) FROM nfts GROUP BY background')
rarity_summary = c.fetchall()
print("\nRarity Summary:")
for bg, count in rarity_summary:
    print(f"  {bg}: {count}")

c.execute('SELECT AVG(attack), AVG(core) FROM nfts')
avg_stats = c.fetchone()
print(f"\nAverage Stats: Attack ~{avg_stats[0]:.1f}, Core ~{avg_stats[1]:.1f}")

conn.close()
print(f"\nDone! Indexed {len(json_files)} files into {DB_PATH}")
print("Query with: python query.py background Gold")